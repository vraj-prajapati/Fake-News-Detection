{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4z8dssQoEbwo"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "loaded_model = load_model('./my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM9-uvSiHgti",
        "outputId": "abb6d1b8-1238-48a0-b7be-b5e76a7dfe83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sachin Tendulkar is a great cricketer\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Predicted Class: [[0.9922362]]\n",
            "Sentence is Sarcastic!!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Example loaded_model and tokenizer\n",
        "# loaded_model = ...  # Your loaded model\n",
        "# Open the file in read mode ('r')\n",
        "with open('file.txt', 'r') as file:\n",
        "    # Read the first line of the file\n",
        "    line = file.readline()\n",
        "   #  while line:\n",
        "   #      print(line)\n",
        "   #      line = file.readline()\n",
        "\n",
        "input_text = line\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([input_text])\n",
        "# Your tokenizer (fitted on training data)\n",
        "\n",
        "# Single input string for prediction\n",
        "\n",
        "\n",
        "# Tokenize and preprocess the input text\n",
        "input_sequence = tokenizer.texts_to_sequences([input_text])\n",
        "input_sequence = pad_sequences(input_sequence, maxlen=100)\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "predictions = loaded_model.predict(input_sequence)\n",
        "\n",
        "# Assuming it's a binary classification task\n",
        "# predicted_class = np.argmax(predictions[0])\n",
        "\n",
        "# Print the predicted class\n",
        "print(\"Predicted Class:\", predictions)\n",
        "if predictions>=0.51:\n",
        "   print(\"Sentence is Sarcastic!!\")\n",
        "else:\n",
        "    print(\"Sentence is not Sarcastic!!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "9GHgGb_qGwbN",
        "outputId": "76e771f3-eae6-47b1-db32-409b70a33e7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a8e86e509a52>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdata_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# Replace with your actual data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mdata_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Remove stop words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mdata_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Convert to lowercase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'apply'"
          ]
        }
      ],
      "source": [
        "# # from nltk.corpus import stopwords\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "# x='Cows lose their jobs as milk prices drop'\n",
        "# stop = stopwords.words('english')\n",
        "# data_clean = data_clean.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) # remove stop words\n",
        "# data_clean = data_clean.apply(lambda x: \" \".join(x.lower() for x in x.split())) # to lower case\n",
        "# data_clean\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the stopwords dataset if you haven't already\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Example text\n",
        "x = 'Cows lose their jobs as milk prices drop'\n",
        "\n",
        "# Define a list of stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# Apply preprocessing steps to the text\n",
        "# Replace 'x' with your actual data_clean variable\n",
        "data_clean = x  # Replace with your actual data\n",
        "\n",
        "data_clean = data_clean.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) # Remove stop words\n",
        "data_clean = data_clean.apply(lambda x: \" \".join(x.lower() for x in x.split())) # Convert to lowercase\n",
        "\n",
        "# Print or use data_clean as needed\n",
        "print(data_clean)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxFxFrsgG1lF"
      },
      "outputs": [],
      "source": [
        "# # vectorizing the data\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# n=1\n",
        "# ngram_range=(n, n)\n",
        "# vectorizer = TfidfVectorizer(ngram_range=ngram_range)\n",
        "# X = vectorizer.fit_transform(data_clean)\n",
        "# tfidf_matrix = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
        "# X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mBW2xDLGeqv"
      },
      "outputs": [],
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# n=1\n",
        "# ngram_range=(n, n)\n",
        "# vectorizer = TfidfVectorizer(ngram_range=ngram_range)\n",
        "# X = vectorizer.fit_transform('Cows lose their jobs as milk prices drop')\n",
        "# # tfidf_matrix = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
        "# X.shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
